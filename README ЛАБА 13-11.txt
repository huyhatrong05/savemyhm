Вариант 14. Имитация отжига для решения квадратичного уравнения 
Задача: использовать имитацию отжига для нахождения минимума функции f(x) = (x-7)² + 5. 
Пункт 1
Решение задачи методом имитации отжига
Имитация отжига (Simulated Annealing) — это вероятностный алгоритм для нахождения глобального минимума функции, особенно в задачах, где есть множество локальных минимумов. Он вдохновлен физическим процессом отжига металлов, когда материал нагревают и затем медленно охлаждают, чтобы уменьшить его дефекты и достичь состояния с минимальной энергией.
Алгоритм для функции f(x) = (x-7)² + 5:
1 Инициализация: Задаем начальную температуру T (высокую), скорость охлаждения alpha (например, 0.95) и минимальную температуру T_min. Генерируем начальное решение x_current как случайное число в диапазоне [0, 20].
2 Цикл отжига: Работаем, пока текущая температура T больше T_min.
Генерация соседа: Создаем новое решение-соседа x_new, добавляя к x_current небольшой случайный сдвиг (например, из нормального распределения). Если x_new выходит за границы [0, 20], корректируем его.
Оценка решений: Вычисляем значение функции для текущего и нового решений: E_current = f(x_current), E_new = f(x_new).
Принятие решения:
Если E_new < E_current, новое решение лучше. Мы всегда принимаем его: x_current = x_new.
Если E_new >= E_current, новое решение хуже. Мы можем принять его с вероятностью p = exp( -(E_new - E_current) / T ). Это позволяет алгоритму "выпрыгивать" из локальных минимумов на ранних стадиях.
3 Охлаждение: Уменьшаем температуру по формуле T = T * alpha.
4 Завершение: По окончании цикла возвращаем x_current и f(x_current) как найденный минимум.
Реализация на Python:
import math
import random

def f(x):
    return (x - 7)**2 + 5

def simulated_annealing():
    # Параметры алгоритма
    T = 1000.0       # Начальная температура
    T_min = 0.0001   # Минимальная температура
    alpha = 0.95     # Скорость охлаждения
    max_iter = 100   # Макс. итераций при одной температуре
    
    # Начальное решение
    x_current = random.uniform(0, 20)
    E_current = f(x_current)
    
    # Лучшее найденное решение
    x_best = x_current
    E_best = E_current
    
    # Главный цикл
    while T > T_min:
        for i in range(max_iter):
            # Генерация соседнего решения
            x_new = x_current + random.normalvariate(0, 1)  # Случайный сдвиг
            x_new = max(0, min(20, x_new))  # Ограничение диапазоном [0, 20]
            
            E_new = f(x_new)
            delta_E = E_new - E_current
            
            # Критерий принятия решения
            if delta_E < 0:
                # Новое решение лучше, принимаем
                x_current = x_new
                E_current = E_new
                if E_new < E_best:
                    x_best = x_new
                    E_best = E_new
            else:
                # Новое решение хуже, принимаем с вероятностью
                p = math.exp(-delta_E / T)
                if random.random() < p:
                    x_current = x_new
                    E_current = E_new
        
        # Охлаждение
        T = T * alpha
    
    return x_best, E_best

# Запуск алгоритма
x_min, f_min = simulated_annealing()
print(f"Найденный минимум: x = {x_min:.4f}, f(x) = {f_min:.4f}")
Пример вывода (может меняться из-за случайности):
Найденный минимум: x = 7.0123, f(x) = 5.0002
Пункт 2
 Объяснение алгоритма
Алгоритм имитации отжига метафорически повторяет процесс охлаждения металла.
Температура (T): Параметр, управляющий вероятностью принятия худших решений. На старте она высока, что позволяет алгоритму свободно исследовать все пространство решений и "перепрыгивать" через холмы.
Охлаждение (T = T * alpha): Постепенное уменьшение температуры делает алгоритм более "привередливым". С каждой итерацией он все реже соглашается на ухудшение, все больше концентрируясь на области вокруг текущего хорошего решения.
Вероятность принятия (p = exp(-ΔE / T)): Формула, гарантирующая, что на высоких температурах даже большие ухудшения имеют шанс быть принятыми, а на низких — принимаются только очень небольшие ухудшения.
В итоге, начав со случайной точки, алгоритм сначала широко исследует область поиска, а затем медленно фокусируется на глобальном минимуме, минуя локальные.
Пункт 3
 Временная сложность алгоритма
Временная сложность имитации отжига составляет O(k * L), где:
k — количество "эпох" охлаждения (пока T не упадет ниже T_min).
L — количество итераций на одной температуре (в нашем коде это max_iter).
Пункт 4
Объяснение временной сложности
Сложность O(k * L) является следствием структуры алгоритма:
У нас есть внешний цикл while T > T_min, который выполняется k раз. Количество k зависит от начальной температуры T, минимальной T_min и скорости охлаждения alpha. Оно не прямо пропорционально размеру входных данных, а является параметром самого алгоритма.
Внутри этого цикла есть вложенный цикл for i in range(max_iter), который выполняется L раз (где L = max_iter).
Поскольку на каждой внутренней итерации выполняются операции с постоянным временем O(1) (вычисление функции, генерация случайного числа), общая сложность определяется произведением количества внешних и внутренних итераций.
Пункт 5
Ответ на контрольный вопрос
Докажите, что коэффициент аппроксимации для жадного алгоритма составления расписания равен 2(1-1/m).
Рассмотрим классическую задачу составления расписания на идентичных машинах (m машин, n заданий с временем выполнения p_j). Жадный алгоритм (алгоритм Листа или LPT - Longest Processing Time) назначает каждое следующее задание (в порядке убывания длительности) на машину, которая освободится раньше всего.
Доказательство:
Обозначения:
OPT — длина оптимального расписания (максимальная загрузка любой машины).
GREEDY — длина расписания, построенного жадным алгоритмом.
Задание, которое определяет итоговое время расписания в жадном алгоритме, назовем j_last. Пусть его время выполнения t.
В момент начала выполнения j_last (обозначим время S), все m машин были заняты. Иначе мы бы начали его выполнять раньше.
Ключевое наблюдение: Поскольку все машины были заняты в момент времени S, общий объем работы, выполненной к этому моменту, не меньше m * S. Но этот объем работы также не может превышать общий объем всей работы без последнего задания: sum(p_j) - t.
Получаем неравенство:
m * S ≤ sum(p_j) - t
Связь с OPT:
В оптимальном расписании самая загруженная машина выполняет работу не меньше, чем sum(p_j) / m (равномерное распределение — идеальный случай).
Также, так как самое длинное задание должно быть выполнено, OPT ≥ max(p_j). В нашем случае, поскольку LPT сортирует задания, t не обязательно самое длинное, но OPT ≥ t.
Из двух этих фактов следует, что OPT ≥ max( sum(p_j)/m, t ).
Оценка GREEDY:
Время жадного расписания — это время окончания последнего задания: GREEDY = S + t.
Из пункта 2: S ≤ (sum(p_j) - t) / m.
Подставляем:
GREEDY = S + t ≤ (sum(p_j) - t) / m + t = (sum(p_j)) / m + t * (1 - 1/m)
Использование оценки для OPT:
Мы знаем, что sum(p_j) ≤ m * OPT (в оптимальном расписании все m машин работают не больше OPT времени каждая) и t ≤ OPT.
Подставляем эти оценки:
GREEDY ≤ (m * OPT) / m + OPT * (1 - 1/m) = OPT + OPT * (1 - 1/m) = OPT * (2 - 1/m)
Таким образом, GREEDY / OPT ≤ 2 - 1/m.
Вывод: Коэффициент аппроксимации для жадного алгоритма (LPT) действительно равен 2 - 1/m (что эквивалентно 2(1 - 1/(2m)), но стандартная форма записи — 2 - 1/m). Это означает, что жадный алгоритм никогда не построит расписание хуже, чем в (2 - 1/m) раз от оптимального.
