1) Задача: создать рекуррентную нейронную сеть (RNN) для генерации текста на
основе обучающего набора.
Задание 7: RNN для генерации текста
Требования:
Использовать LSTM ячейки (128 units)
Embedding layer для векторизации символов
Предсказание следующего символа
Управление температурой при генерации
2) Алгоритм и архитектура работы НС по блокам
Нужно построить простую RNN для генерации текста по обучающему набору. Ниже — краткий алгоритм и архитектура по блокам для типичной символьной (или словарной) модели.

**Подготовка данных**
Собрать обучающий текст в одну большую строку и построить словарь символов (или слов).​
Построить отображения символ → индекс и индекс → символ.​
Разбить текст на перекрывающиеся последовательности длины 
T: вход X — первые 
T символов, цель Y — следующий символ после них.​
Закодировать X в one‑hot или с помощью embedding (размерность: (кол-во_примеров, T, размер_словаря) при one‑hot).​

**Архитектура сети**
Входной слой: принимает тензор формы (batch, T) с индексами или (batch, T, vocab_size) при one‑hot.​
(Опционально) Embedding-слой: преобразует индекс символа в плотный вектор признаков.​
RNN-слой: SimpleRNN, LSTM или GRU, обрабатывающий последовательность по шагам времени и формирующий скрытое состояние 
Полносвязный (Dense) слой: принимает последнее скрытое состояние (или все состояния) и выдаёт логиты размером vocab_size.​
Softmax: преобразует логиты в распределение вероятностей по следующему символу.
Пример (Keras): Embedding → LSTM → Dense(vocab_size) → Softmax
Обучение
Функция потерь: кросс‑энтропия по распределению softmax и истинному следующему символу.​
Оптимизатор: например RMSprop или Adam, обучение мини‑батчами.​
На каждом шаге: подать батч последовательностей, получить предсказания для каждого шага, посчитать среднюю потерю, выполнить обратное распространение через время (BPTT) и обновить веса.​

**Алгоритм генерации текста**
Выбрать начальную строку (seed): либо фиксированную, либо случайный фрагмент обучающего текста.​
Преобразовать seed в индексы и подать в обученную RNN, получив распределение вероятностей по следующему символу.​
Выбрать следующий символ:
либо максимум вероятности (argmax);
либо случайная выборка с регулировкой “температуры” для разнообразия.​
Добавить выбранный символ к текущему тексту, сдвинуть окно последнего контекста длины 
T и снова подать в сеть. Повторять до нужной длины текста или до появления токена конца.

**Логическая блок‑схема работы**
Блок 1: Входной текст → предобработка → формирование пар (последовательность, следующий символ).​
Блок 2: НС: слой представления (one‑hot/Embedding) → RNN (LSTM/GRU) → Dense → Softmax.​
Блок 3: Обучение: вычисление ошибки (кросс‑энтропия) → BPTT → обновление весов.​
Блок 4: Генерация: начальное состояние и seed → итеративное предсказание следующего символа → сбор выходной строки.

3) контрольные вопросы, Что такое теорема Ардена и для чего она используется?
Теорема Ардена относится к теории конечных автоматов и регулярных языков. Она используется для преобразования конечного автомата в эквивалентное регулярное выражение с помощью системы уравнений на языках.
Суть теоремы
Теорема Ардена рассматривает уравнение на языках вида
R=Q+RP,
P — регулярные языки (или регулярные выражения), и пустое слово не входит в 
P. В этом случае уравнение имеет единственное решение 
R=QP 
∗Интуитивно это означает, что если язык 
R состоит из всех слов, которые либо принадлежат Q, либо получаются как слово из R с последующим словом из P, то весь R можно описать как «слова из Q, за которыми следует любое количество повторений языка P».​
Для чего используется
Теорема Ардена применяется при решении систем уравнений, возникающих при поиске регулярного выражения по заданному детерминированному конечному автомату. Для каждого состояния автомата записывается уравнение для языка, принимаемого из этого состояния, через переходы и языки на рёбрах, а затем эта система уравнений пошагово решается с помощью теоремы Ардена. В результате получают регулярное выражение, описывающее язык, распознаваемый автоматом.​
Также теорема Ардена является инструментом для доказательства эквивалентности конечных автоматов и регулярных выражений: она обеспечивает конструктивный метод перехода от автомата к выражению. В учебных курсах по теории автоматов её используют как основной алгоритмический приём систематического «выведения» регулярного выражения из сложного автомата, особенно когда в графе есть петли (циклы), которые приводят к уравнениям вида 
X=AX+B.​​
